{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   mpg           398 non-null    float64\n",
      " 1   cylinders     398 non-null    int64  \n",
      " 2   displacement  398 non-null    float64\n",
      " 3   horsepower    398 non-null    object \n",
      " 4   weight        398 non-null    int64  \n",
      " 5   acceleration  398 non-null    float64\n",
      " 6   model year    398 non-null    int64  \n",
      " 7   origin        398 non-null    int64  \n",
      " 8   car name      398 non-null    object \n",
      "dtypes: float64(3), int64(4), object(2)\n",
      "memory usage: 28.1+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Univariate Analysis: 100%|██████████| 9/9 [00:03<00:00,  2.68it/s]\n",
      "Bivariate Analysis: 100%|██████████| 9/9 [00:00<00:00, 5975.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDA Report generated successfully as 'EDA_Report.pptx'\n"
     ]
    }
   ],
   "source": [
    "def load_data(file, sheet_name=None, encoding='utf-8'):\n",
    "    \"\"\"\n",
    "    Load data from a CSV, Excel, or JSON file.\n",
    "\n",
    "    Parameters:\n",
    "    - file: str, path to the file\n",
    "    - sheet_name: str, sheet name if the file is an Excel file (default is None)\n",
    "    - encoding: str, encoding of the file (default is 'utf-8')\n",
    "\n",
    "    Returns:\n",
    "    - df: pandas DataFrame\n",
    "    \"\"\"\n",
    "    if file.endswith('.csv'):\n",
    "        df = pd.read_csv(file, encoding=encoding)\n",
    "    elif file.endswith('.xlsx'):\n",
    "        df = pd.read_excel(file, sheet_name=sheet_name, encoding=encoding)\n",
    "    elif file.endswith('.json'):\n",
    "        df = pd.read_json(file, encoding=encoding)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format\")\n",
    "    return df\n",
    "\n",
    "def statistics(df):\n",
    "    \"\"\"\n",
    "    Generate basic statistics for the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "\n",
    "    Returns:\n",
    "    - desc: DataFrame, descriptive statistics\n",
    "    - info: None, prints info about the DataFrame\n",
    "    - unique_counts: Series, count of unique values per column\n",
    "    \"\"\"\n",
    "    desc = df.describe()\n",
    "    info = df.info()\n",
    "    unique_counts = df.nunique()\n",
    "    return desc, info, unique_counts\n",
    "\n",
    "def missing_values(df, save_to_memory=True):\n",
    "    \"\"\"\n",
    "    Perform missing values analysis and plot the results.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "    - save_to_memory: bool, whether to save the plot in memory or locally (default is True)\n",
    "\n",
    "    Returns:\n",
    "    - missing_df: DataFrame, missing values and their percentages\n",
    "    - buf or filepath: BytesIO buffer or str, path to the saved plot\n",
    "    \"\"\"\n",
    "    missing = df.isnull().sum()\n",
    "    total = df.shape[0]\n",
    "    missing_percentage = (missing / total) * 100\n",
    "    missing_df = pd.DataFrame({'Missing Values': missing, 'Percentage': missing_percentage})\n",
    "    \n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    missing_df.plot(kind='barh', stacked=True, ax=ax)\n",
    "    plt.title('Missing Values Analysis')\n",
    "    plt.xlabel('Count')\n",
    "    if save_to_memory:\n",
    "        buf = BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        plt.close()\n",
    "        buf.seek(0)\n",
    "        return missing_df, buf\n",
    "    else:\n",
    "        plt.savefig('missing_values.png')\n",
    "        plt.close()\n",
    "        return missing_df, 'missing_values.png'\n",
    "\n",
    "def univariate_analysis(df, nunique_threshold=15, save_to_memory=True):\n",
    "    \"\"\"\n",
    "    Perform univariate analysis and plot the results.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "    - nunique_threshold: int, threshold for number of unique values to consider for countplot (default is 15)\n",
    "    - save_to_memory: bool, whether to save the plots in memory or locally (default is True)\n",
    "\n",
    "    Returns:\n",
    "    - plots: list of tuples, containing plot titles and BytesIO buffers or file paths\n",
    "    \"\"\"\n",
    "    plots = []\n",
    "    for column in tqdm(df.columns, desc=\"Univariate Analysis\"):\n",
    "        if df[column].dtype == 'object' and df[column].nunique() < nunique_threshold:\n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "            sns.countplot(y=df[column], ax=ax)\n",
    "            plt.title(f'Count Plot of {column}')\n",
    "            if save_to_memory:\n",
    "                buf = BytesIO()\n",
    "                plt.savefig(buf, format='png')\n",
    "                plt.close()\n",
    "                buf.seek(0)\n",
    "                plots.append((f'Count Plot of {column}', buf))\n",
    "            else:\n",
    "                if not os.path.exists('univariate'):\n",
    "                    os.makedirs('univariate')\n",
    "                plt.savefig(f'univariate/countplot_{column}.png')\n",
    "                plt.close()\n",
    "                plots.append((f'Count Plot of {column}', f'univariate/countplot_{column}.png'))\n",
    "        elif df[column].dtype != 'object':\n",
    "            fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "            sns.histplot(df[column], kde=True, ax=axs[0])\n",
    "            axs[0].set_title(f'Histogram of {column}')\n",
    "            sns.boxplot(x=df[column], ax=axs[1])\n",
    "            axs[1].set_title(f'Boxplot of {column}')\n",
    "            if save_to_memory:\n",
    "                buf = BytesIO()\n",
    "                plt.savefig(buf, format='png')\n",
    "                plt.close()\n",
    "                buf.seek(0)\n",
    "                plots.append((f'Univariate Analysis of {column}', buf))\n",
    "            else:\n",
    "                if not os.path.exists('univariate'):\n",
    "                    os.makedirs('univariate')\n",
    "                plt.savefig(f'univariate/univariate_{column}.png')\n",
    "                plt.close()\n",
    "                plots.append((f'Univariate Analysis of {column}', f'univariate/univariate_{column}.png'))\n",
    "    return plots\n",
    "\n",
    "def bivariate_analysis(df, nunique_threshold=15, save_to_memory=True):\n",
    "    \"\"\"\n",
    "    Perform bivariate analysis and plot the results.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "    - nunique_threshold: int, threshold for number of unique values to consider for categorical plots (default is 15)\n",
    "    - save_to_memory: bool, whether to save the plots in memory or locally (default is True)\n",
    "\n",
    "    Returns:\n",
    "    - plots: list of tuples, containing plot titles and BytesIO buffers or file paths\n",
    "    \"\"\"\n",
    "    plots = []\n",
    "    for column in tqdm(df.columns, desc=\"Bivariate Analysis\"):\n",
    "        if df[column].dtype == 'object' and df[column].nunique() < nunique_threshold:\n",
    "            for num_column in df.select_dtypes(include=np.number).columns:\n",
    "                fig, ax = plt.subplots(figsize=(10, 6))\n",
    "                sns.boxplot(x=df[column], y=df[num_column], ax=ax)\n",
    "                plt.title(f'{column} vs {num_column}')\n",
    "                if save_to_memory:\n",
    "                    buf = BytesIO()\n",
    "                    plt.savefig(buf, format='png')\n",
    "                    plt.close()\n",
    "                    buf.seek(0)\n",
    "                    plots.append((f'{column} vs {num_column}', buf))\n",
    "                else:\n",
    "                    if not os.path.exists('bivariate'):\n",
    "                        os.makedirs('bivariate')\n",
    "                    plt.savefig(f'bivariate/bivariate_{column}_vs_{num_column}.png')\n",
    "                    plt.close()\n",
    "                    plots.append((f'{column} vs {num_column}', f'bivariate/bivariate_{column}_vs_{num_column}.png'))\n",
    "    return plots\n",
    "\n",
    "def plot_corr(df, annot=True, cmap='RdYlGn', center=0, square=True, save_to_memory=True):\n",
    "    \"\"\"\n",
    "    Plot a heatmap correlation plot.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "    - annot: bool, whether to annotate the heatmap with correlation values (default is True)\n",
    "    - cmap: str, colormap for the heatmap (default is 'RdYlGn')\n",
    "    - center: float, center value for the colormap (default is 0)\n",
    "    - square: bool, whether to force the plot to be square (default is True)\n",
    "    - save_to_memory: bool, whether to save the plot in memory or locally (default is True)\n",
    "\n",
    "    Returns:\n",
    "    - buf or filepath: BytesIO buffer or str, path to the saved plot\n",
    "    \"\"\"\n",
    "    num_df = df.select_dtypes(include=np.number)\n",
    "    corr = num_df.corr()\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    sns.heatmap(corr, mask=mask, cmap=cmap, annot=annot, center=center, square=square)\n",
    "    plt.tight_layout()\n",
    "    if save_to_memory:\n",
    "        buf = BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        plt.close()\n",
    "        buf.seek(0)\n",
    "        return buf\n",
    "    else:\n",
    "        if not os.path.exists('multivariate'):\n",
    "            os.makedirs('multivariate')\n",
    "        plt.savefig('multivariate/correlation_heatmap.png')\n",
    "        plt.close()\n",
    "        return 'multivariate/correlation_heatmap.png'\n",
    "\n",
    "def create_pptx(missing_buf, univariate_plots, bivariate_plots, corr_buf):\n",
    "    \"\"\"\n",
    "    Create a PowerPoint presentation with the generated plots.\n",
    "\n",
    "    Parameters:\n",
    "    - missing_buf: BytesIO buffer, plot buffer for missing values\n",
    "    - univariate_plots: list of tuples, plot buffers for univariate analysis\n",
    "    - bivariate_plots: list of tuples, plot buffers for bivariate analysis\n",
    "    - corr_buf: BytesIO buffer, plot buffer for correlation heatmap\n",
    "\n",
    "    Returns:\n",
    "    - None, saves the PowerPoint presentation as 'EDA_Report.pptx'\n",
    "    \"\"\"\n",
    "    prs = Presentation()\n",
    "    \n",
    "    # Slide for missing values\n",
    "    slide_layout = prs.slide_layouts[5] # Use a title and content layout\n",
    "    slide = prs.slides.add_slide(slide_layout)\n",
    "    title = slide.shapes.title\n",
    "    title.text = \"Missing Values Analysis\"\n",
    "    slide.shapes.add_picture(missing_buf, Inches(1), Inches(1.5), height=Inches(5.5))\n",
    "\n",
    "    # Slides for univariate analysis\n",
    "    for title_text, plot_buf in univariate_plots:\n",
    "        slide = prs.slides.add_slide(slide_layout)\n",
    "        title = slide.shapes.title\n",
    "        title.text = title_text\n",
    "        slide.shapes.add_picture(plot_buf, Inches(1), Inches(1.5), height=Inches(5.5))\n",
    "\n",
    "    # Slides for bivariate analysis\n",
    "    for title_text, plot_buf in bivariate_plots:\n",
    "        slide = prs.slides.add_slide(slide_layout)\n",
    "        title = slide.shapes.title\n",
    "        title.text = title_text\n",
    "        slide.shapes.add_picture(plot_buf, Inches(1), Inches(1.5), height=Inches(5.5))\n",
    "\n",
    "    # Slide for correlation heatmap\n",
    "    slide = prs.slides.add_slide(slide_layout)\n",
    "    title = slide.shapes.title\n",
    "    title.text = \"Correlation Heatmap\"\n",
    "    slide.shapes.add_picture(corr_buf, Inches(1), Inches(1.5), height=Inches(5.5))\n",
    "    \n",
    "    prs.save('EDA_Report.pptx')\n",
    "\n",
    "def main(file, sheet_name=None, encoding='utf-8', nunique_threshold=15, save_to_memory=True, perform_univariate=True, perform_bivariate=True, perform_multivariate=True, columns=None):\n",
    "    \"\"\"\n",
    "    Main function to perform Exploratory Data Analysis (EDA) on a given dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - file (str): Path to the dataset file.\n",
    "    - sheet_name (str, optional): Name of the sheet in an Excel file. Default is None.\n",
    "    - encoding (str, optional): Encoding of the dataset file. Default is 'utf-8'.\n",
    "    - nunique_threshold (int, optional): Threshold for the number of unique values to consider for countplot. Default is 15.\n",
    "    - save_to_memory (bool, optional): Whether to save the plots in memory or locally. Default is True.\n",
    "    - perform_univariate (bool, optional): Whether to perform univariate analysis. Default is True.\n",
    "    - perform_bivariate (bool, optional): Whether to perform bivariate analysis. Default is True.\n",
    "    - perform_multivariate (bool, optional): Whether to perform multivariate analysis. Default is True.\n",
    "    - columns (list, optional): List of column names to consider for analysis. Default is None.\n",
    "\n",
    "    Returns:\n",
    "    - None: Prints a success message when the EDA report is generated.\n",
    "    \"\"\"\n",
    "    df = load_data(file, sheet_name, encoding)\n",
    "    \n",
    "    if columns:\n",
    "        df = df[columns]\n",
    "    \n",
    "    desc, info, unique_counts = statistics(df)\n",
    "    missing_df, missing_buf = missing_values(df, save_to_memory)\n",
    "    \n",
    "    univariate_plots = []\n",
    "    if perform_univariate:\n",
    "        univariate_plots = univariate_analysis(df, nunique_threshold, save_to_memory)\n",
    "    \n",
    "    bivariate_plots = []\n",
    "    if perform_bivariate:\n",
    "        bivariate_plots = bivariate_analysis(df, nunique_threshold, save_to_memory)\n",
    "    \n",
    "    corr_buf = None\n",
    "    if perform_multivariate:\n",
    "        corr_buf = plot_corr(df, save_to_memory=save_to_memory)\n",
    "    \n",
    "    create_pptx(missing_buf, univariate_plots, bivariate_plots, corr_buf)\n",
    "    print(\"EDA Report generated successfully as 'EDA_Report.pptx'\")\n",
    "\n",
    "# Run the pipeline\n",
    "file = r\"C:\\Users\\Asif Sayyed\\Documents\\GitHub\\MachineLearns\\data\\auto-mpg.csv\"  # replace with your file path\n",
    "main(file, nunique_threshold=15, save_to_memory=False, perform_univariate=True, perform_bivariate=True, perform_multivariate=True, columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path, encoding='utf-8'):\n",
    "    \"\"\"\n",
    "    Load data from a specified file path. Supports CSV, Excel, JSON, and Parquet files.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path (str): Path to the file to be loaded.\n",
    "    - encoding (str): Encoding to be used for reading the file. Default is 'utf-8'.\n",
    "    \n",
    "    Returns:\n",
    "    - dict or DataFrame: A dictionary of DataFrames with keys being sheet names for Excel files,\n",
    "                         or a single DataFrame for other file types.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"The file at {file_path} does not exist.\")\n",
    "    \n",
    "    file_extension = os.path.splitext(file_path)[1].lower()\n",
    "    \n",
    "    try:\n",
    "        if file_extension == '.csv':\n",
    "            data = pd.read_csv(file_path, encoding=encoding)\n",
    "            data.columns = data.columns.str.lower()\n",
    "        elif file_extension in ['.xls', '.xlsx']:\n",
    "            data = pd.read_excel(file_path, sheet_name=None)\n",
    "        elif file_extension == '.json':\n",
    "            with open(file_path, 'r', encoding=encoding) as f:\n",
    "                json_data = json.load(f)\n",
    "            data = pd.json_normalize(json_data)\n",
    "            data.columns = data.columns.str.lower()\n",
    "        elif file_extension == '.parquet':\n",
    "            data = pd.read_parquet(file_path)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file extension: {file_extension}\")\n",
    "    except UnicodeDecodeError as e:\n",
    "        raise ValueError(f\"Error loading the file due to encoding issues: {e}\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error loading the file: {e}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "def sanitize_sheet_name(sheet_name):\n",
    "    \"\"\"\n",
    "    Sanitize the sheet name to be a valid Python variable name and convert to lowercase.\n",
    "    \n",
    "    Parameters:\n",
    "    - sheet_name (str): Original sheet name.\n",
    "    \n",
    "    Returns:\n",
    "    - str: Sanitized sheet name.\n",
    "    \"\"\"\n",
    "    return re.sub(r'\\W|^(?=\\d)', '_', sheet_name.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_df(dataframe, head=5):\n",
    "    \"\"\"\n",
    "    Function to check basic characteristics of a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    - dataframe: pandas.core.DataFrame\n",
    "        DataFrame to be checked.\n",
    "    - head: int\n",
    "        Number of rows to display from the beginning and end of the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    Example Usage:\n",
    "    --------------\n",
    "    check_df(df, head=10)\n",
    "    \"\"\"\n",
    "    print(\"################## Shape ####################\")\n",
    "    print(dataframe.shape)\n",
    "    print(\"################## Types ####################\")\n",
    "    print(dataframe.dtypes)\n",
    "    print(\"################## Head ####################\")\n",
    "    display(dataframe.head(head))\n",
    "    print(\"################## Tail ####################\")\n",
    "    display(dataframe.tail(head))\n",
    "    print(\"################## NA ####################\")\n",
    "    print(dataframe.isnull().sum())\n",
    "    print(\"################## Quantiles ####################\")\n",
    "    display(dataframe.describe([0.05, 0.10, 0.25, 0.40, 0.50, 0.60, 0.75, 0.90, 0.95]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = r\"D:\\College\\Academics\\Extra\\Datasets\\daily-total-female-births.csv\"\n",
    "# path = r\"D:\\College\\Academics\\Extra\\Datasets\\test.xlsx\"\n",
    "path = r\"D:\\College\\Academics\\SEM 4\\New Generation Database\\Datasets\\playstore.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>births</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1959-01-01</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1959-01-02</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1959-01-03</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1959-01-04</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1959-01-05</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  births\n",
       "0  1959-01-01      35\n",
       "1  1959-01-02      32\n",
       "2  1959-01-03      30\n",
       "3  1959-01-04      31\n",
       "4  1959-01-05      44"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#reading csv or json\n",
    "df = load_data(path)\n",
    "display(df.head())\n",
    "\n",
    "# excel_data = load_data(path)\n",
    "# for sheet_name, df in excel_data.items():\n",
    "#     sanitized_name = sanitize_sheet_name(sheet_name)\n",
    "#     globals()[sanitized_name] = df\n",
    "#     print(f\"DataFrame '{sanitized_name}' created:\")\n",
    "#     display(globals()[sanitized_name].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################## Shape ####################\n",
      "(365, 2)\n",
      "################## Types ####################\n",
      "date      object\n",
      "births     int64\n",
      "dtype: object\n",
      "################## Head ####################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>births</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1959-01-01</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1959-01-02</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1959-01-03</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1959-01-04</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1959-01-05</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  births\n",
       "0  1959-01-01      35\n",
       "1  1959-01-02      32\n",
       "2  1959-01-03      30\n",
       "3  1959-01-04      31\n",
       "4  1959-01-05      44"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################## Tail ####################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>births</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>1959-12-27</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>1959-12-28</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>1959-12-29</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>1959-12-30</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>1959-12-31</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  births\n",
       "360  1959-12-27      37\n",
       "361  1959-12-28      52\n",
       "362  1959-12-29      48\n",
       "363  1959-12-30      55\n",
       "364  1959-12-31      50"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################## NA ####################\n",
      "date      0\n",
      "births    0\n",
      "dtype: int64\n",
      "################## Quantiles ####################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>5%</th>\n",
       "      <th>10%</th>\n",
       "      <th>25%</th>\n",
       "      <th>40%</th>\n",
       "      <th>50%</th>\n",
       "      <th>60%</th>\n",
       "      <th>75%</th>\n",
       "      <th>90%</th>\n",
       "      <th>95%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>births</th>\n",
       "      <td>365.0</td>\n",
       "      <td>41.980822</td>\n",
       "      <td>7.348257</td>\n",
       "      <td>23.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>33.4</td>\n",
       "      <td>37.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>51.6</td>\n",
       "      <td>55.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count       mean       std   min    5%   10%   25%   40%   50%   60%  \\\n",
       "births  365.0  41.980822  7.348257  23.0  31.0  33.4  37.0  40.0  42.0  44.0   \n",
       "\n",
       "         75%   90%   95%   max  \n",
       "births  46.0  51.6  55.0  73.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "check_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
